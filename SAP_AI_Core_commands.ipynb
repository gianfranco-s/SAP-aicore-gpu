{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e67bf95-d4c7-400b-b271-ed502c4372a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from ai_api_client_sdk.exception import AIAPINotFoundException, AIAPIServerException\n",
    "\n",
    "from sapaicore_utils import (DOCKER_TOKEN,\n",
    "                             DOCKER_USER,\n",
    "                             get_conn_details,\n",
    "                             GITHUB_TOKEN,\n",
    "                             GITHUB_USER,\n",
    "                             onboard_repository,\n",
    "                             onboard_docker,\n",
    "                             show_docker_registries,\n",
    "                             show_repositories,)\n",
    "\n",
    "conn_details = get_conn_details()\n",
    "ai_core_client = AICoreV2Client(**conn_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472bcbee",
   "metadata": {},
   "source": [
    "## Step 0. Onboard a repository and Docker account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905b611",
   "metadata": {},
   "source": [
    "### GitHub repository\n",
    "We'll need a GitHub username and token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be294b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sap-training-ncellini\n",
      "URL: https://github.com/NCellini/aicore-pipelines\n",
      "Status: RepositoryStatus.COMPLETED\n",
      "\n",
      "Name: gsalomone-tf-gpu\n",
      "URL: https://github.com/gianfranco-s/SAP-aicore-gpu\n",
      "Status: RepositoryStatus.COMPLETED\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, let's see which repositories have been onboarded\n",
    "show_repositories(ai_core_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f532b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'gsalomone-tf-gpu'\n",
    "github_repo_url = 'https://github.com/gianfranco-s/SAP-aicore-gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0bf811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository already exists\n"
     ]
    }
   ],
   "source": [
    "# If project does not exist, AIAPINotFoundException is raised when `get()` is invoked\n",
    "try:\n",
    "    ai_core_client.repositories.get(PROJECT_NAME)\n",
    "    print('Repository already exists')\n",
    "\n",
    "except AIAPINotFoundException:\n",
    "    onboard_repository(github_repo_url,\n",
    "                    GITHUB_USER,\n",
    "                    GITHUB_TOKEN,\n",
    "                    PROJECT_NAME,\n",
    "                    ai_core_client)\n",
    "    print('Repository created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9eb0ea",
   "metadata": {},
   "source": [
    "### Docker account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4abed6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DockerRegistrySecret name: credstutorialrepo-ncellini\n",
      "DockerRegistrySecret name: gsalomone-docker\n"
     ]
    }
   ],
   "source": [
    "# First, let's see which registries have been onboarded\n",
    "show_docker_registries(ai_core_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50ce0742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker registry already exists\n"
     ]
    }
   ],
   "source": [
    "docker_registry_name = 'gsalomone-docker'\n",
    "\n",
    "# If project does not exist, AIAPINotFoundException is raised when `get()` is invoked\n",
    "try:\n",
    "    ai_core_client.docker_registry_secrets.get(docker_registry_name)\n",
    "    print('Docker registry already exists')\n",
    "\n",
    "except AIAPINotFoundException:\n",
    "    onboard_docker(docker_registry_name, DOCKER_USER, DOCKER_TOKEN, ai_core_client)\n",
    "    print('Docker registry created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03fec94",
   "metadata": {},
   "source": [
    "## Step 1. Create workspace\n",
    "Using default resource group because when I tried to create `tf-demo`, I got the message \"Resource Group cannot be created for free tier tenant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef95d95a-d6b4-445a-b708-d30a670bcfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to post /admin/resourceGroups: Resource Group cannot be created for free tier tenant \n",
      " Status Code: 403, Request ID:None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = ai_core_client.resource_groups.create(\"tf-demo\")\n",
    "\n",
    "except AIAPIServerException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7fff6d7-94ff-416c-a781-e45d31a05e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    }
   ],
   "source": [
    "def show_resource_groups() -> None:\n",
    "    response = ai_core_client.resource_groups.query()\n",
    "\n",
    "    for rg in response.resources:\n",
    "        print(rg.resource_group_id)\n",
    "\n",
    "show_resource_groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90aef5d-58f4-4a61-801d-6f46b6ba13d3",
   "metadata": {},
   "source": [
    "## Step 2: upload model files to AWS S3\n",
    "Create bucket\n",
    "```\n",
    "aws s3api create-bucket --bucket gsalomone-celestial-bucket --region us-east-1\n",
    "```\n",
    "\n",
    "Upload files\n",
    "```\n",
    "cd tf_files\n",
    "aws s3 cp model.h5 s3://gsalomone-celestial-bucket/movie-clf/model/\n",
    "aws s3 cp max_pad_len.txt s3://gsalomone-celestial-bucket/movie-clf/model/\n",
    "aws s3 cp label_encoded_classes.npy s3://gsalomone-celestial-bucket/movie-clf/model/\n",
    "aws s3 cp tokens.json s3://gsalomone-celestial-bucket/movie-clf/model/\n",
    "```\n",
    "\n",
    "Check files\n",
    "```\n",
    "aws s3 ls s3://gsalomone-celestial-bucket/movie-clf/model/\n",
    "```\n",
    "\n",
    "Alternatively, it can be done using the AWS SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def upload_file_to_s3(file_dir: str, file_name: str, bucket_name: str, s3_key: str) -> None:\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        s3.upload_file(file_dir + file_name, bucket_name, s3_key + file_name)\n",
    "        print(f\"File uploaded successfully to S3 bucket: {bucket_name} with key: {s3_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "bucket_name = 'gsalomone-celestial-bucket'\n",
    "s3_key = 'movie-clf/model/'\n",
    "file_dir = 'tf_files/'\n",
    "\n",
    "upload_file_to_s3(file_dir, 'model.h5', bucket_name, s3_key)\n",
    "upload_file_to_s3(file_dir, 'max_pad_len.txt', bucket_name, s3_key)\n",
    "upload_file_to_s3(file_dir, 'label_encoded_classes.npy', bucket_name, s3_key)\n",
    "upload_file_to_s3(file_dir, 'tokens.json', bucket_name, s3_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b94cf5e",
   "metadata": {},
   "source": [
    "## Step 3: connect AWS S3 to SAP AI Core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c93e76a-a7d8-4896-a0e9-a81caea935de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws_credentials_file = '/home/gsalomone/Documents/gian-dev_accessKeys.csv'\n",
    "aws_credentials_file = '/home/gian/gian-dev_accessKeys.csv'\n",
    "\n",
    "def get_aws_credentials(filepath: str) -> tuple:\n",
    "    with open(filepath, 'r') as f:\n",
    "        creds = f.readlines()[1:2][0]\n",
    "        aws_access_key_id, aws_secret_access_key = creds.split(',')\n",
    "        return aws_access_key_id, aws_secret_access_key\n",
    "\n",
    "aws_access_key_id, aws_secret_access_key = get_aws_credentials(aws_credentials_file)\n",
    "aws_az = 'us-east-1'\n",
    "object_store_name = 'gs-tf-gpu-tutorial-secret'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e1e4a-7b98-4a1b-91f6-f22df8462577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_s3_object_store() -> str:\n",
    "    response = ai_core_client.object_store_secrets.create(\n",
    "        resource_group = 'default',\n",
    "        type = \"S3\",\n",
    "        name = object_store_name,\n",
    "        path_prefix = \"movie-clf\",\n",
    "        endpoint = f\"s3-{aws_az}.amazonaws.com\",\n",
    "        bucket = \"gsalomone-celestial-bucket\",\n",
    "        region = aws_az,\n",
    "        data = {\n",
    "            \"AWS_ACCESS_KEY_ID\": aws_access_key_id,\n",
    "            \"AWS_SECRET_ACCESS_KEY\": aws_secret_access_key\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response.message\n",
    "\n",
    "res = create_s3_object_store()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2139160",
   "metadata": {},
   "source": [
    "## Step 4: register model as Artifact\n",
    "Let's follow the tutorial to the letter.\n",
    "\n",
    "Spoiler: it will not work. **We'll follow step 6 first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72320208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model as artifact\n",
    "from ai_core_sdk.models import Artifact\n",
    "\n",
    "def create_model(model_name: str, object_store_name: str, scenario_id: str, description: str) -> str:\n",
    "    \"\"\"Create artifact as model\n",
    "    \n",
    "    Keyword arguments:\n",
    "    model_name -- self explanatory\n",
    "    object_store_name -- s3 object store\n",
    "    scenario_id -- taken form the yaml file, found under `scenarios.ai.sap.com/id`\n",
    "    Return: return_description\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ai_core_client.artifact.create(\n",
    "        resource_group = 'default',\n",
    "        name = model_name,\n",
    "        kind = Artifact.Kind.MODEL,\n",
    "        url = f\"ai://{object_store_name}/model\",\n",
    "        scenario_id = scenario_id,\n",
    "        description = description\n",
    "    )\n",
    "    return response.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    msg = create_model(model_name='gsalomone-model',\n",
    "                       scenario_id='tf-text-clf',\n",
    "                       description='Review Classification Model',\n",
    "                       object_store_name=object_store_name,)\n",
    "\n",
    "    print(msg)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b0580",
   "metadata": {},
   "source": [
    "### Step 4 -> Step 6: we need to set up the scenario_id FIRST\n",
    "It turns out that `scenario_id` is created from the yaml file. So we'll move to step 6 of the tutorial\n",
    "\n",
    "- Copy [`serving_executable.yaml`](https://raw.githubusercontent.com/sap-tutorials/Tutorials/master/tutorials/ai-core-tensorflow-byod/files/workflow/serving_executable.yaml)\n",
    "- set `resourcePlan` to `infer.s` which will enable GPU. ATTENTION: free tier only allows for `starter`\n",
    "- set `imagePullSecrets > name` to the appropriate docker registry secret. In this tutorial you'll find it in variable `docker_registry_name`\n",
    "- set `containers > image` is set to `\"docker.io/DOCKER_USER/movie-review-clf-serve:0.0.1\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945ec69",
   "metadata": {},
   "source": [
    "### Step 4 -> Step 7: sync with SAP AI Core\n",
    "- Push `serving_executable.yaml` to GitHub\n",
    "- Create the application in SAP AI Core\n",
    "- Check for typos in yaml file `executables.ai.sap.com/name: \"serve-executuable\"` -> `executables.ai.sap.com/name: \"serve-executable\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80064c3a-b1e0-4b60-b872-55775fc255c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create application\n",
    "application_name = 'gsalomone-tf-app'\n",
    "response = ai_core_client.applications.create(\n",
    "    application_name = application_name,\n",
    "    revision = \"HEAD\",\n",
    "    repository_url = github_repo_url,\n",
    "    path = \"tf-text-classifier\"  # path to the yaml file in the repository\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21675f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9ae74-3fd3-4b60-9c71-8c5bdb9a593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ai_core_client.applications.get_status(application_name=application_name)\n",
    "print(response.message)\n",
    "\n",
    "for workflow_sync_status in response.sync_ressources_status:\n",
    "    print(f'\\napplication status: ', workflow_sync_status.status)\n",
    "    print(f'workflow message: ', workflow_sync_status.message)\n",
    "    print(f'application name (from yaml file): ', workflow_sync_status.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c00b06",
   "metadata": {},
   "source": [
    "### Step 4 -> Step 4: NOW register model as artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d2184-ab79-432d-a287-a1abc0186ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO_ID = 'tf-text-clf'  # Remember to take it from the yaml file: `scenarios.ai.sap.com/id`\n",
    "msg = create_model(model_name='gsalomone-model',\n",
    "                    scenario_id=SCENARIO_ID,\n",
    "                    description='Review Classification Model',\n",
    "                    object_store_name=object_store_name,)\n",
    "\n",
    "print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show artifacts\n",
    "\n",
    "from datetime import datetime\n",
    "artifacts = ai_core_client.artifact.query(resource_group='default')\n",
    "\n",
    "artifact_resources = artifacts.resources\n",
    "\n",
    "for resource in artifact_resources:\n",
    "    print(f\"artifact_id: {resource.id}\")\n",
    "    print(f\"created_at: {resource.created_at}\")\n",
    "    print(f\"execution_id: {resource.execution_id}\")\n",
    "    print(f\"kind: {resource.kind}\")\n",
    "    print(f\"name: {resource.name}\")\n",
    "    print(f\"scenario_id: {resource.scenario_id}\")\n",
    "    print(f\"url: {resource.url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab0e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest artifact is apparently at the top of the list, so let's define\n",
    "artifact_id = artifact_resources[0].id\n",
    "artifact_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9feeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just showing another way to get artifact data\n",
    "from pprint import pprint\n",
    "\n",
    "res = ai_core_client.artifact.get(artifact_id=artifact_id, resource_group='default')\n",
    "pprint(res.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56878e",
   "metadata": {},
   "source": [
    "## Step 5: set up serving code\n",
    "```\n",
    "cd server\n",
    "sudo docker login docker.io  # Password is the Personal Access Token\n",
    "sudo docker build -t docker.io/gsalomone/movie-review-clf-serve:0.0.1 .\n",
    "sudo docker push docker.io/gsalomone/movie-review-clf-serve:0.0.1\n",
    "```\n",
    "- Modify requirements to install latest versions\n",
    "- Use flag `--ignore-installed` in Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188cab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755d2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56c4125c",
   "metadata": {},
   "source": [
    "## Step 8: create configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37bf0d-1677-47cb-8a08-a680d3e73b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create configuration\n",
    "from ai_core_sdk.models import InputArtifactBinding\n",
    "\n",
    "EXECUTABLE_ID = \"tf-text-clf-serve\"  # It's the (first) `name` key in the yaml file\n",
    "\n",
    "response = ai_core_client.configuration.create(\n",
    "    name = \"gsalomone-tf-gpu-conf\",\n",
    "    resource_group = \"default\",\n",
    "    scenario_id = SCENARIO_ID,\n",
    "    executable_id = EXECUTABLE_ID,\n",
    "    input_artifact_bindings = [\n",
    "        # list\n",
    "        InputArtifactBinding(key=\"modelArtifact\", artifact_id = artifact_id), # Change artifact id\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.__dict__)\n",
    "config_id = response.__dict__.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f687cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = ai_core_client.configuration.query(resource_group='default')\n",
    "\n",
    "\n",
    "for resource in configurations.resources:\n",
    "    pprint(resource.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, apparently the latest resource appears at the top, so\n",
    "configuration_id = configurations.resources[0].id\n",
    "configuration_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf24265",
   "metadata": {},
   "source": [
    "## Step 9: start deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c716d6d9-8114-4390-8233-7feb055c6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ai_core_client.deployment.create(\n",
    "    resource_group = \"default\",\n",
    "    configuration_id = configuration_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployments = ai_core_client.deployment.query(resource_group=\"default\")\n",
    "\n",
    "# Following what we've learned about the query method:\n",
    "deployment_id = deployments.resources[0].id\n",
    "deployment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2bbc8-3712-462e-b3a6-171d9e712100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check deployment status\n",
    "# This may take 2-3 minutes to change state from UNKNOWN > PENDING > RUNNING.\n",
    "\n",
    "response = ai_core_client.deployment.get(resource_group=\"default\", deployment_id=deployment_id)\n",
    "\n",
    "print(\"Status: \", response.status)\n",
    "print('*'*80)\n",
    "pprint(response.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76670765-6d38-4a7b-87b9-38b60e187115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
